import cv2
import numpy as np
import time
import os

# --- C·∫§U H√åNH QUAN TR·ªåNG ---
# 1. IP c·ªßa ESP32 khi ·ªü ch·∫ø ƒë·ªô t·ª± ph√°t Wifi (AP Mode)
# C·ªïng l√† 80, ƒë∆∞·ªùng d·∫´n l√† /stream nh∆∞ code Arduino ƒë√£ n·∫°p
CAMERA_URL = "http://192.168.4.1:80/stream"

# 2. T√™n file model .tflite b·∫°n ƒë√£ t·∫£i v·ªÅ
MODEL_PATH = "saurang_pi_final.tflite"

# 3. K√≠ch th∆∞·ªõc ·∫£nh training (B·∫Øt bu·ªôc ph·∫£i kh·ªõp v·ªõi l√∫c train tr√™n Colab)
IMG_SIZE = 224

# 4. ƒê·ªô nh·∫°y (0.5 l√† trung b√¨nh, n·∫øu nhi·ªÖu qu√° th√¨ tƒÉng l√™n 0.6 ho·∫∑c 0.7)
CONFIDENCE = 0.5 

# --- NH·∫¨P TH∆Ø VI·ªÜN AI ---
print("‚öôÔ∏è Dang nap thu vien AI...")
try:
    # ∆Øu ti√™n d√πng tflite_runtime (Nh·∫π cho Pi)
    import tflite_runtime.interpreter as tflite
except ImportError:
    try:
        # N·∫øu ƒëang test tr√™n laptop c√†i full tensorflow
        import tensorflow.lite as tflite
    except ImportError:
        print("‚ùå L·ªñI: Chua cai thu vien AI!")
        print("üëâ Hay chay lenh: pip3 install tflite-runtime")
        exit()

def main():
    # 1. LOAD MODEL
    print(f"üîÑ Dang load model: {MODEL_PATH}...")
    if not os.path.exists(MODEL_PATH):
        print(f"‚ùå L·ªñI: Khong tim thay file '{MODEL_PATH}'")
        return

    try:
        interpreter = tflite.Interpreter(model_path=MODEL_PATH)
        interpreter.allocate_tensors()
    except Exception as e:
        print(f"‚ùå L·ªói load model: {e}")
        return

    # L·∫•y th√¥ng s·ªë input/output
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    
    # 2. K·∫æT N·ªêI CAMERA (V√≤ng l·∫∑p ƒë·ªÉ th·ª≠ l·∫°i n·∫øu m·∫•t k·∫øt n·ªëi)
    while True:
        print(f"üì° Dang ket noi toi ESP32-CAM: {CAMERA_URL}")
        print("‚ö†Ô∏è Luu y: Pi phai dang ket noi Wifi 'NhaKhoa_Raspi' nhe!")
        
        cap = cv2.VideoCapture(CAMERA_URL)

        if not cap.isOpened():
            print("‚ùå Khong the ket noi Camera! Dang thu lai sau 2 giay...")
            time.sleep(2)
            continue
        
        print("‚úÖ DA KET NOI THANH CONG! Bat dau soi rang...")
        print("‚ÑπÔ∏è Nhan phim 'q' hoac 'Esc' de thoat.")

        # Bi·∫øn ƒë·∫øm FPS
        prev_time = 0

        while True:
            ret, frame = cap.read()
            
            # N·∫øu m·∫•t t√≠n hi·ªáu h√¨nh ·∫£nh
            if not ret:
                print("‚ö†Ô∏è Mat tin hieu tu ESP32! Dang thu ket noi lai...")
                break # Tho√°t v√≤ng l·∫∑p ƒë·ªçc ·∫£nh ƒë·ªÉ quay l·∫°i v√≤ng l·∫∑p k·∫øt n·ªëi

            # --- GIAI ƒêO·∫†N X·ª¨ L√ù AI ---
            try:
                # 1. Resize ·∫£nh v·ªÅ chu·∫©n 224x224
                img_resized = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))
                
                # 2. Chu·∫©n h√≥a v·ªÅ 0-1 v√† ƒë·ªãnh d·∫°ng float32
                input_data = np.expand_dims(img_resized, axis=0).astype(np.float32) / 255.0

                # 3. ƒê∆∞a v√†o Model
                interpreter.set_tensor(input_details[0]['index'], input_data)
                
                # 4. Ch·∫°y d·ª± ƒëo√°n (Inference)
                interpreter.invoke()
                
                # 5. L·∫•y k·∫øt qu·∫£ mask
                output_data = interpreter.get_tensor(output_details[0]['index'])[0]
                
                # 6. X·ª≠ l√Ω Mask (Ng∆∞·ª°ng l·ªçc)
                # output_data l√† ·∫£nh m·ªù 224x224. Ch·ªó n√†o > 0.5 l√† s√¢u rƒÉng
                mask = (output_data > CONFIDENCE).astype(np.uint8) * 255
                
                # Resize mask v·ªÅ b·∫±ng k√≠ch th∆∞·ªõc khung h√¨nh th·∫≠t c·ªßa Camera (VGA 640x480)
                mask_overlay = cv2.resize(mask, (frame.shape[1], frame.shape[0]), interpolation=cv2.INTER_NEAREST)

                # --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ ---
                # C√°ch 1: V·∫Ω vi·ªÅn ƒë·ªè
                contours, _ = cv2.findContours(mask_overlay, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(frame, contours, -1, (0, 0, 255), 2) # Vi·ªÅn ƒë·ªè ƒë·∫≠m

                # C√°ch 2: T√¥ m√†u ƒë·ªè b√°n trong su·ªët
                if np.any(mask_overlay): # Ch·ªâ t√¥ n·∫øu ph√°t hi·ªán s√¢u rƒÉng
                    zeros = np.zeros_like(mask_overlay)
                    # T·∫°o ·∫£nh m√†u ƒë·ªè (BGR: 0, 0, 255)
                    mask_color = cv2.merge([zeros, zeros, mask_overlay])
                    # Tr·ªôn ·∫£nh g·ªëc v√† m√†u ƒë·ªè
                    frame = cv2.addWeighted(frame, 1, mask_color, 0.5, 0)
                    
                    # Hi·ªán ch·ªØ c·∫£nh b√°o
                    cv2.putText(frame, "PHAT HIEN SAU RANG!", (50, 50), 
                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)

            except Exception as e:
                print(f"L·ªói x·ª≠ l√Ω ·∫£nh: {e}")

            # T√≠nh v√† hi·ªán FPS
            curr_time = time.time()
            fps = 1 / (curr_time - prev_time)
            prev_time = curr_time
            cv2.putText(frame, f"FPS: {int(fps)}", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

            cv2.imshow("He Thong Soi Rang (Pi + ESP32)", frame)

            # Ph√≠m tho√°t
            key = cv2.waitKey(1)
            if key == ord('q') or key == 27: # q ho·∫∑c Esc
                cap.release()
                cv2.destroyAllWindows()
                return # Tho√°t ch∆∞∆°ng tr√¨nh

        cap.release() # Gi·∫£i ph√≥ng camera ƒë·ªÉ k·∫øt n·ªëi l·∫°i

if __name__ == "__main__":
    main()
